{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (1.18.5)\n",
      "Requirement already satisfied: xlrd in /opt/conda/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.1.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy xlrd pandas matplotlib seaborn sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import your Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-5-7cf2d3dd9c7a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-7cf2d3dd9c7a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    df = pd.read_csv('https://raw.githubusercontent.com/fenago/pythonml/main/data/CleanCreditScoring.csv)\u001b[0m\n\u001b[0m                                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 1\n",
    "# Load your data  -- start with CreditScoring.csv... then online retail\n",
    "#df = pd.read_csv('https://raw.githubusercontent.com/fenago/pythonml/main/data/CleanCreditScoring.csv)\n",
    "#  you can also pull from urls like this:   \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/fenago/MLEssentials/main/datasets/Life%20Expectancy%20Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "This session covers data collection and some procedures of data preparation. \n",
    "\n",
    "**Commands, functions, and methods:** \n",
    "\n",
    "* `!wget` - Linux shell command for downloading data \n",
    "* `pd.read.csv()` - read csv files \n",
    "* `df.head()` - take a look of the dataframe \n",
    "* `df.head().T` - take a look of the transposed dataframe \n",
    "* `df.columns` - retrieve column names of a dataframe \n",
    "* `df.columns.str.lower()` - lowercase all the letters \n",
    "* `df.columns.str.replace(' ', '_')` - replace the space separator \n",
    "* `df.dtypes` - retrieve data types of all series \n",
    "* `df.index` - retrive indices of a dataframe\n",
    "* `pd.to_numeric()` - convert a series values to numerical values. The `errors=coerce` argument allows making the transformation despite some encountered errors. \n",
    "* `df.fillna()` - replace NAs with some value \n",
    "* `(df.x == \"yes\").astype(int)` - convert x series of yes-no values to numerical values.\n",
    "* `df['Weight'] = df['Weight'].astype(int)` - this takes a single column of data and converts the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Cleaning\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_') # A\n",
    " \n",
    "string_columns = list(df.dtypes[df.dtypes == 'object'].index) # B\n",
    " \n",
    "for col in string_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_') # C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE THAT YOU WRANGLE YOUR DATA.  THIS IS AN EXAMPLE OF THE TYPES OF THINGS THAT ARE NEEDED\n",
    "# SKIP THIS CEL - IT IS ONLY TO REITERATE THE NEED TO CLEAN \n",
    "# For instance - in the CreditScoring dataset - there are numerous 99999999 that need to be replaced\n",
    "# Obviously don't run this with your dataset\n",
    "# for c in ['income', 'assets', 'debt']:\n",
    "#    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n",
    "#df = df[df.status != 'unk']   # Also make sure to treat the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Visuals so you can gain a business understanding of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your target variable --- df.YOUR_TARGET_VARIABLE  \n",
    "# Look for major data imbalances\n",
    "# Also replace your X label\n",
    "# REPLACE YOUR TARGET VARIABLE\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "sns.histplot(df.<replace with your target variable>, bins=40, color='black', alpha=1)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('<replace with your target variable>')\n",
    "plt.title('PUT A LABEL ON IT')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "* (1) Check for NaN under a single DataFrame column:\n",
    "\n",
    "* `df['your column name'].isnull().values.any()`\n",
    "\n",
    "* (2) Count the NaN under a single DataFrame column:\n",
    "\n",
    "`df['your column name'].isnull().sum()`\n",
    "\n",
    "* (3) Check for NaN under an entire DataFrame:\n",
    "\n",
    "`df.isnull().values.any()`\n",
    "\n",
    "* (4) Count the NaN under an entire DataFrame:\n",
    "\n",
    "`df.isnull().sum().sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls --- you do NOT want nulls when you train\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the percentage of missing values\n",
    "df.isnull().sum() / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Value Counts\n",
    "# df.\"REPLACE WITH FIELD NAME\".value_counts()\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns --- this may or may NOT be needed.  As before - skip if you don't need it\n",
    "# You will encounter times where you will want to delete columns.  This is how you do that.\n",
    "# df = df.drop(['x5_latitude', 'x6_longitude', 'x1_transaction_date'], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "# i.e.:  address = London, UK\n",
    "# df[['city', 'country']] = df['address'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change any Data Types\n",
    "#Replace Data Types to Integer\n",
    "# df[\"Customer Number\"] = df['Customer Number'].astype('int')\n",
    "#Replace Data Types to String\n",
    "# df[\"Customer Number\"] = df['Customer Number'].astype('str')\n",
    "#Replace Data Types to Boolean\n",
    "# df[\"IsPurchased\"] = df['IsPurchased'].astype('bool')\n",
    "#Replace Data Types to Float\n",
    "# df[\"Total Spend\"] = df['Total Spend'].astype('float')\n",
    "#Replace Data Types to Datetime with format= '%Y%m%d'\n",
    "# df['Dates'] = pd.to_datetime(df['Dates'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STICK TO CATEGORICAL COLUMNS INITIALLY\n",
    "#plot the histogram to see the distribution of the point data.\n",
    "sns.displot(data, x=\"YOUR_VARIABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"YOUR_VARIABLE\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YOUR_VARIABLE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure its skewness and kurtosis\n",
    "data['YOUR_VARIABLE'].agg(['skew', 'kurtosis']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for outliers\n",
    "ax = sns.boxplot(x=data[\"YOUR_VARIABLE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://miro.medium.com/max/1400/1*_aN1iaiVUTdoyPbyj-kVjA.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 2 variables to compare and replace SEX and DEFAULT WITH THE TWO VARIABLES\n",
    "# Stick with Categorical variables for now\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "edu = sns.countplot(x='SEX', hue='DEFAULT', data=df)\n",
    "edu.set_xticklabels(['Male','Female'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Cross Tab\n",
    "pd.crosstab(df.SEX,df.DEFAULT,normalize='index',margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson Correlation\n",
    "corrMatrix = df.corr()\n",
    "sns.heatmap(corrMatrix, annot = True, cmap= 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman Correlation\n",
    "sns.set(rc={'figure.figsize':(30,10)})\n",
    "sns.set_context(\"talk\", font_scale=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.iloc[:,1:].corr(method='spearman'), cmap='rainbow_r', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the Correlation between your variable of interest and the rest of the variables\n",
    "# - replace \"DEFAULT\" with your variable of interest.\n",
    "df.drop(\"DEFAULT\", axis=1).apply(lambda x: x.corr(df.DEFAULT,method='spearman'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
